{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_acc_time(X_train, X_test, y_train, y_test, model):\n",
    "    # creates a model based on training data and returns the accuracy on the held out test set and the time it took to train the model\n",
    "    # data should be pre processed already\n",
    "    \n",
    "    # records the time and accuracy for each model, as well as saving the model itself\n",
    "    total_time = []\n",
    "    accuracy = []\n",
    "    models = []\n",
    "\n",
    "    # manual 5 fold on test data to select the best model\n",
    "    for i in range(5):\n",
    "        # splitting the training data to train and evaluate the model\n",
    "        kfX_train, kfX_test, kfy_train, kfy_test = train_test_split(\n",
    "    X_train, y_train, test_size=0.2,shuffle=True)\n",
    "\n",
    "        # creates a new unfitted model with the inputted parameters\n",
    "        curModel = sklearn.base.clone(model)\n",
    "\n",
    "\n",
    "        # times the training of the model and calcualtes the accuracy on the validation set\n",
    "        t1 = time.time()\n",
    "        curModel.fit(kfX_train,kfy_train)\n",
    "        accuracy.append((curModel.predict(kfX_test)==np.array(kfy_test)[0]).mean())\n",
    "        t2 = time.time()\n",
    "        models.append(curModel)\n",
    "        total_time.append(t2-t1)\n",
    "\n",
    "    # selects the model with the highest accuracy on the validation set and calcuates the accuracy on the held out set\n",
    "    best_index = accuracy.index(max(accuracy))\n",
    "    t = total_time[best_index]\n",
    "    most_acc_model = models[best_index]\n",
    "    acc = (most_acc_model.predict(X_test)==np.array(y_test)[0]).mean()*100\n",
    "\n",
    "    return \"Accuracy: {0:.2f}% || Time to Train: {1:.3f} seconds\".format(acc, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0          0.289    -0.0203    -0.1330     -0.995    -0.9830     -0.914   \n",
       "1          0.278    -0.0164    -0.1240     -0.998    -0.9750     -0.960   \n",
       "2          0.280    -0.0195    -0.1130     -0.995    -0.9670     -0.979   \n",
       "3          0.279    -0.0262    -0.1230     -0.996    -0.9830     -0.991   \n",
       "4          0.277    -0.0166    -0.1150     -0.998    -0.9810     -0.990   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "10294      0.310    -0.0534    -0.0991     -0.288    -0.1410     -0.215   \n",
       "10295      0.363    -0.0392    -0.1060     -0.305     0.0281     -0.196   \n",
       "10296      0.350     0.0301    -0.1160     -0.330    -0.0421     -0.250   \n",
       "10297      0.238     0.0185    -0.0965     -0.323    -0.2300     -0.208   \n",
       "10298      0.154    -0.0184    -0.1370     -0.330    -0.1950     -0.164   \n",
       "\n",
       "       feature_7  feature_8  feature_9  feature_10  ...  feature_553  \\\n",
       "0         -0.995     -0.983     -0.924    -0.93500  ...      -0.2990   \n",
       "1         -0.999     -0.975     -0.958    -0.94300  ...      -0.5950   \n",
       "2         -0.997     -0.964     -0.977    -0.93900  ...      -0.3910   \n",
       "3         -0.997     -0.983     -0.989    -0.93900  ...      -0.1170   \n",
       "4         -0.998     -0.980     -0.990    -0.94200  ...      -0.3510   \n",
       "...          ...        ...        ...         ...  ...          ...   \n",
       "10294     -0.356     -0.149     -0.232     0.18500  ...      -0.3760   \n",
       "10295     -0.374     -0.030     -0.270     0.18500  ...      -0.3200   \n",
       "10296     -0.388     -0.133     -0.347     0.00747  ...      -0.1190   \n",
       "10297     -0.392     -0.280     -0.289     0.00747  ...      -0.2050   \n",
       "10298     -0.431     -0.218     -0.230    -0.11200  ...      -0.0722   \n",
       "\n",
       "       feature_554  feature_555  feature_556  feature_557  feature_558  \\\n",
       "0           -0.710      -0.1130      0.03040       -0.465      -0.0184   \n",
       "1           -0.861       0.0535     -0.00743       -0.733       0.7040   \n",
       "2           -0.760      -0.1190      0.17800        0.101       0.8090   \n",
       "3           -0.483      -0.0368     -0.01290        0.640      -0.4850   \n",
       "4           -0.699       0.1230      0.12300        0.694      -0.6160   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "10294       -0.751      -0.3370      0.34600        0.885      -0.6990   \n",
       "10295       -0.700      -0.7370     -0.37300       -0.657       0.3230   \n",
       "10296       -0.467      -0.1820      0.08860        0.697       0.3630   \n",
       "10297       -0.618       0.4450     -0.81900        0.929      -0.0084   \n",
       "10298       -0.437       0.5990     -0.28800        0.876      -0.0250   \n",
       "\n",
       "       feature_559  feature_560  feature_561  activity  \n",
       "0           -0.841        0.180      -0.0586         5  \n",
       "1           -0.845        0.180      -0.0543         5  \n",
       "2           -0.849        0.181      -0.0491         5  \n",
       "3           -0.849        0.182      -0.0477         5  \n",
       "4           -0.848        0.185      -0.0439         5  \n",
       "...            ...          ...          ...       ...  \n",
       "10294       -0.652        0.275       0.1850         2  \n",
       "10295       -0.655        0.274       0.1820         2  \n",
       "10296       -0.655        0.274       0.1810         2  \n",
       "10297       -0.660        0.265       0.1880         2  \n",
       "10298       -0.660        0.264       0.1880         2  \n",
       "\n",
       "[10299 rows x 562 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>feature_8</th>\n      <th>feature_9</th>\n      <th>feature_10</th>\n      <th>...</th>\n      <th>feature_553</th>\n      <th>feature_554</th>\n      <th>feature_555</th>\n      <th>feature_556</th>\n      <th>feature_557</th>\n      <th>feature_558</th>\n      <th>feature_559</th>\n      <th>feature_560</th>\n      <th>feature_561</th>\n      <th>activity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.289</td>\n      <td>-0.0203</td>\n      <td>-0.1330</td>\n      <td>-0.995</td>\n      <td>-0.9830</td>\n      <td>-0.914</td>\n      <td>-0.995</td>\n      <td>-0.983</td>\n      <td>-0.924</td>\n      <td>-0.93500</td>\n      <td>...</td>\n      <td>-0.2990</td>\n      <td>-0.710</td>\n      <td>-0.1130</td>\n      <td>0.03040</td>\n      <td>-0.465</td>\n      <td>-0.0184</td>\n      <td>-0.841</td>\n      <td>0.180</td>\n      <td>-0.0586</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.278</td>\n      <td>-0.0164</td>\n      <td>-0.1240</td>\n      <td>-0.998</td>\n      <td>-0.9750</td>\n      <td>-0.960</td>\n      <td>-0.999</td>\n      <td>-0.975</td>\n      <td>-0.958</td>\n      <td>-0.94300</td>\n      <td>...</td>\n      <td>-0.5950</td>\n      <td>-0.861</td>\n      <td>0.0535</td>\n      <td>-0.00743</td>\n      <td>-0.733</td>\n      <td>0.7040</td>\n      <td>-0.845</td>\n      <td>0.180</td>\n      <td>-0.0543</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.280</td>\n      <td>-0.0195</td>\n      <td>-0.1130</td>\n      <td>-0.995</td>\n      <td>-0.9670</td>\n      <td>-0.979</td>\n      <td>-0.997</td>\n      <td>-0.964</td>\n      <td>-0.977</td>\n      <td>-0.93900</td>\n      <td>...</td>\n      <td>-0.3910</td>\n      <td>-0.760</td>\n      <td>-0.1190</td>\n      <td>0.17800</td>\n      <td>0.101</td>\n      <td>0.8090</td>\n      <td>-0.849</td>\n      <td>0.181</td>\n      <td>-0.0491</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.279</td>\n      <td>-0.0262</td>\n      <td>-0.1230</td>\n      <td>-0.996</td>\n      <td>-0.9830</td>\n      <td>-0.991</td>\n      <td>-0.997</td>\n      <td>-0.983</td>\n      <td>-0.989</td>\n      <td>-0.93900</td>\n      <td>...</td>\n      <td>-0.1170</td>\n      <td>-0.483</td>\n      <td>-0.0368</td>\n      <td>-0.01290</td>\n      <td>0.640</td>\n      <td>-0.4850</td>\n      <td>-0.849</td>\n      <td>0.182</td>\n      <td>-0.0477</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.277</td>\n      <td>-0.0166</td>\n      <td>-0.1150</td>\n      <td>-0.998</td>\n      <td>-0.9810</td>\n      <td>-0.990</td>\n      <td>-0.998</td>\n      <td>-0.980</td>\n      <td>-0.990</td>\n      <td>-0.94200</td>\n      <td>...</td>\n      <td>-0.3510</td>\n      <td>-0.699</td>\n      <td>0.1230</td>\n      <td>0.12300</td>\n      <td>0.694</td>\n      <td>-0.6160</td>\n      <td>-0.848</td>\n      <td>0.185</td>\n      <td>-0.0439</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10294</th>\n      <td>0.310</td>\n      <td>-0.0534</td>\n      <td>-0.0991</td>\n      <td>-0.288</td>\n      <td>-0.1410</td>\n      <td>-0.215</td>\n      <td>-0.356</td>\n      <td>-0.149</td>\n      <td>-0.232</td>\n      <td>0.18500</td>\n      <td>...</td>\n      <td>-0.3760</td>\n      <td>-0.751</td>\n      <td>-0.3370</td>\n      <td>0.34600</td>\n      <td>0.885</td>\n      <td>-0.6990</td>\n      <td>-0.652</td>\n      <td>0.275</td>\n      <td>0.1850</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10295</th>\n      <td>0.363</td>\n      <td>-0.0392</td>\n      <td>-0.1060</td>\n      <td>-0.305</td>\n      <td>0.0281</td>\n      <td>-0.196</td>\n      <td>-0.374</td>\n      <td>-0.030</td>\n      <td>-0.270</td>\n      <td>0.18500</td>\n      <td>...</td>\n      <td>-0.3200</td>\n      <td>-0.700</td>\n      <td>-0.7370</td>\n      <td>-0.37300</td>\n      <td>-0.657</td>\n      <td>0.3230</td>\n      <td>-0.655</td>\n      <td>0.274</td>\n      <td>0.1820</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10296</th>\n      <td>0.350</td>\n      <td>0.0301</td>\n      <td>-0.1160</td>\n      <td>-0.330</td>\n      <td>-0.0421</td>\n      <td>-0.250</td>\n      <td>-0.388</td>\n      <td>-0.133</td>\n      <td>-0.347</td>\n      <td>0.00747</td>\n      <td>...</td>\n      <td>-0.1190</td>\n      <td>-0.467</td>\n      <td>-0.1820</td>\n      <td>0.08860</td>\n      <td>0.697</td>\n      <td>0.3630</td>\n      <td>-0.655</td>\n      <td>0.274</td>\n      <td>0.1810</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10297</th>\n      <td>0.238</td>\n      <td>0.0185</td>\n      <td>-0.0965</td>\n      <td>-0.323</td>\n      <td>-0.2300</td>\n      <td>-0.208</td>\n      <td>-0.392</td>\n      <td>-0.280</td>\n      <td>-0.289</td>\n      <td>0.00747</td>\n      <td>...</td>\n      <td>-0.2050</td>\n      <td>-0.618</td>\n      <td>0.4450</td>\n      <td>-0.81900</td>\n      <td>0.929</td>\n      <td>-0.0084</td>\n      <td>-0.660</td>\n      <td>0.265</td>\n      <td>0.1880</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10298</th>\n      <td>0.154</td>\n      <td>-0.0184</td>\n      <td>-0.1370</td>\n      <td>-0.330</td>\n      <td>-0.1950</td>\n      <td>-0.164</td>\n      <td>-0.431</td>\n      <td>-0.218</td>\n      <td>-0.230</td>\n      <td>-0.11200</td>\n      <td>...</td>\n      <td>-0.0722</td>\n      <td>-0.437</td>\n      <td>0.5990</td>\n      <td>-0.28800</td>\n      <td>0.876</td>\n      <td>-0.0250</td>\n      <td>-0.660</td>\n      <td>0.264</td>\n      <td>0.1880</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>10299 rows × 562 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "phoneData = pd.read_csv(\"data/phone_activity.csv\")\n",
    "phoneData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6    0.188756\n",
       "5    0.185067\n",
       "4    0.172541\n",
       "1    0.167201\n",
       "2    0.149917\n",
       "3    0.136518\n",
       "Name: activity, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "phoneData.activity.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "feature_1     1.000000   0.128072  -0.230328   0.004609  -0.016769  -0.036030   \n",
       "feature_2     0.128072   1.000000  -0.029915  -0.046341  -0.046985  -0.054130   \n",
       "feature_3    -0.230328  -0.029915   1.000000  -0.024208  -0.023758  -0.015666   \n",
       "feature_4     0.004609  -0.046341  -0.024208   1.000000   0.922528   0.861910   \n",
       "feature_5    -0.016769  -0.046985  -0.023758   0.922528   1.000000   0.888255   \n",
       "...                ...        ...        ...        ...        ...        ...   \n",
       "feature_558   0.034320   0.077609  -0.030737  -0.027118  -0.015783  -0.012185   \n",
       "feature_559  -0.041054  -0.007518   0.003152  -0.374103  -0.381385  -0.353274   \n",
       "feature_560   0.034039  -0.005606  -0.012893   0.449439   0.506122   0.459099   \n",
       "feature_561   0.030661  -0.016230  -0.028325   0.393059   0.425500   0.483420   \n",
       "activity     -0.004497   0.037329   0.043543  -0.729099  -0.816075  -0.775704   \n",
       "\n",
       "             feature_7  feature_8  feature_9  feature_10  ...  feature_553  \\\n",
       "feature_1     0.010310  -0.017470  -0.038760    0.046960  ...    -0.006087   \n",
       "feature_2    -0.045239  -0.047667  -0.055507   -0.039436  ...    -0.000669   \n",
       "feature_3    -0.022899  -0.022989  -0.009615   -0.040246  ...     0.023110   \n",
       "feature_4     0.998661   0.916087   0.856496    0.981227  ...     0.165541   \n",
       "feature_5     0.918562   0.997510   0.887053    0.911141  ...     0.220249   \n",
       "...                ...        ...        ...         ...  ...          ...   \n",
       "feature_558  -0.027106  -0.013406  -0.012783   -0.030903  ...    -0.013063   \n",
       "feature_559  -0.371169  -0.378016  -0.355844   -0.384243  ...    -0.085205   \n",
       "feature_560   0.444943   0.507964   0.460362    0.458845  ...     0.087657   \n",
       "feature_561   0.389469   0.424472   0.480028    0.402871  ...     0.058737   \n",
       "activity     -0.725420  -0.817348  -0.781064   -0.729709  ...    -0.220326   \n",
       "\n",
       "             feature_554  feature_555  feature_556  feature_557  feature_558  \\\n",
       "feature_1      -0.002169    -0.553002     0.015760     0.036136     0.034320   \n",
       "feature_2      -0.002855     0.077742    -0.027572     0.013229     0.077609   \n",
       "feature_3       0.023186     0.055028    -0.042151    -0.066246    -0.030737   \n",
       "feature_4       0.135161    -0.034337    -0.017084     0.027459    -0.027118   \n",
       "feature_5       0.191141    -0.020811    -0.006602     0.001901    -0.015783   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "feature_558    -0.011829    -0.027495     0.023605    -0.112461     1.000000   \n",
       "feature_559    -0.081957     0.008042     0.017521    -0.007100     0.024815   \n",
       "feature_560     0.078005     0.003101    -0.007239    -0.006456    -0.004576   \n",
       "feature_561     0.054001    -0.003234    -0.013146    -0.015371    -0.012552   \n",
       "activity       -0.207847    -0.007791     0.016710     0.020079     0.014390   \n",
       "\n",
       "             feature_559  feature_560  feature_561  activity  \n",
       "feature_1      -0.041054     0.034039     0.030661 -0.004497  \n",
       "feature_2      -0.007518    -0.005606    -0.016230  0.037329  \n",
       "feature_3       0.003152    -0.012893    -0.028325  0.043543  \n",
       "feature_4      -0.374103     0.449439     0.393059 -0.729099  \n",
       "feature_5      -0.381385     0.506122     0.425500 -0.816075  \n",
       "...                  ...          ...          ...       ...  \n",
       "feature_558     0.024815    -0.004576    -0.012552  0.014390  \n",
       "feature_559     1.000000    -0.748247    -0.635230  0.613556  \n",
       "feature_560    -0.748247     1.000000     0.545612 -0.605585  \n",
       "feature_561    -0.635230     0.545612     1.000000 -0.534107  \n",
       "activity        0.613556    -0.605585    -0.534107  1.000000  \n",
       "\n",
       "[562 rows x 562 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_1</th>\n      <th>feature_2</th>\n      <th>feature_3</th>\n      <th>feature_4</th>\n      <th>feature_5</th>\n      <th>feature_6</th>\n      <th>feature_7</th>\n      <th>feature_8</th>\n      <th>feature_9</th>\n      <th>feature_10</th>\n      <th>...</th>\n      <th>feature_553</th>\n      <th>feature_554</th>\n      <th>feature_555</th>\n      <th>feature_556</th>\n      <th>feature_557</th>\n      <th>feature_558</th>\n      <th>feature_559</th>\n      <th>feature_560</th>\n      <th>feature_561</th>\n      <th>activity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>feature_1</th>\n      <td>1.000000</td>\n      <td>0.128072</td>\n      <td>-0.230328</td>\n      <td>0.004609</td>\n      <td>-0.016769</td>\n      <td>-0.036030</td>\n      <td>0.010310</td>\n      <td>-0.017470</td>\n      <td>-0.038760</td>\n      <td>0.046960</td>\n      <td>...</td>\n      <td>-0.006087</td>\n      <td>-0.002169</td>\n      <td>-0.553002</td>\n      <td>0.015760</td>\n      <td>0.036136</td>\n      <td>0.034320</td>\n      <td>-0.041054</td>\n      <td>0.034039</td>\n      <td>0.030661</td>\n      <td>-0.004497</td>\n    </tr>\n    <tr>\n      <th>feature_2</th>\n      <td>0.128072</td>\n      <td>1.000000</td>\n      <td>-0.029915</td>\n      <td>-0.046341</td>\n      <td>-0.046985</td>\n      <td>-0.054130</td>\n      <td>-0.045239</td>\n      <td>-0.047667</td>\n      <td>-0.055507</td>\n      <td>-0.039436</td>\n      <td>...</td>\n      <td>-0.000669</td>\n      <td>-0.002855</td>\n      <td>0.077742</td>\n      <td>-0.027572</td>\n      <td>0.013229</td>\n      <td>0.077609</td>\n      <td>-0.007518</td>\n      <td>-0.005606</td>\n      <td>-0.016230</td>\n      <td>0.037329</td>\n    </tr>\n    <tr>\n      <th>feature_3</th>\n      <td>-0.230328</td>\n      <td>-0.029915</td>\n      <td>1.000000</td>\n      <td>-0.024208</td>\n      <td>-0.023758</td>\n      <td>-0.015666</td>\n      <td>-0.022899</td>\n      <td>-0.022989</td>\n      <td>-0.009615</td>\n      <td>-0.040246</td>\n      <td>...</td>\n      <td>0.023110</td>\n      <td>0.023186</td>\n      <td>0.055028</td>\n      <td>-0.042151</td>\n      <td>-0.066246</td>\n      <td>-0.030737</td>\n      <td>0.003152</td>\n      <td>-0.012893</td>\n      <td>-0.028325</td>\n      <td>0.043543</td>\n    </tr>\n    <tr>\n      <th>feature_4</th>\n      <td>0.004609</td>\n      <td>-0.046341</td>\n      <td>-0.024208</td>\n      <td>1.000000</td>\n      <td>0.922528</td>\n      <td>0.861910</td>\n      <td>0.998661</td>\n      <td>0.916087</td>\n      <td>0.856496</td>\n      <td>0.981227</td>\n      <td>...</td>\n      <td>0.165541</td>\n      <td>0.135161</td>\n      <td>-0.034337</td>\n      <td>-0.017084</td>\n      <td>0.027459</td>\n      <td>-0.027118</td>\n      <td>-0.374103</td>\n      <td>0.449439</td>\n      <td>0.393059</td>\n      <td>-0.729099</td>\n    </tr>\n    <tr>\n      <th>feature_5</th>\n      <td>-0.016769</td>\n      <td>-0.046985</td>\n      <td>-0.023758</td>\n      <td>0.922528</td>\n      <td>1.000000</td>\n      <td>0.888255</td>\n      <td>0.918562</td>\n      <td>0.997510</td>\n      <td>0.887053</td>\n      <td>0.911141</td>\n      <td>...</td>\n      <td>0.220249</td>\n      <td>0.191141</td>\n      <td>-0.020811</td>\n      <td>-0.006602</td>\n      <td>0.001901</td>\n      <td>-0.015783</td>\n      <td>-0.381385</td>\n      <td>0.506122</td>\n      <td>0.425500</td>\n      <td>-0.816075</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>feature_558</th>\n      <td>0.034320</td>\n      <td>0.077609</td>\n      <td>-0.030737</td>\n      <td>-0.027118</td>\n      <td>-0.015783</td>\n      <td>-0.012185</td>\n      <td>-0.027106</td>\n      <td>-0.013406</td>\n      <td>-0.012783</td>\n      <td>-0.030903</td>\n      <td>...</td>\n      <td>-0.013063</td>\n      <td>-0.011829</td>\n      <td>-0.027495</td>\n      <td>0.023605</td>\n      <td>-0.112461</td>\n      <td>1.000000</td>\n      <td>0.024815</td>\n      <td>-0.004576</td>\n      <td>-0.012552</td>\n      <td>0.014390</td>\n    </tr>\n    <tr>\n      <th>feature_559</th>\n      <td>-0.041054</td>\n      <td>-0.007518</td>\n      <td>0.003152</td>\n      <td>-0.374103</td>\n      <td>-0.381385</td>\n      <td>-0.353274</td>\n      <td>-0.371169</td>\n      <td>-0.378016</td>\n      <td>-0.355844</td>\n      <td>-0.384243</td>\n      <td>...</td>\n      <td>-0.085205</td>\n      <td>-0.081957</td>\n      <td>0.008042</td>\n      <td>0.017521</td>\n      <td>-0.007100</td>\n      <td>0.024815</td>\n      <td>1.000000</td>\n      <td>-0.748247</td>\n      <td>-0.635230</td>\n      <td>0.613556</td>\n    </tr>\n    <tr>\n      <th>feature_560</th>\n      <td>0.034039</td>\n      <td>-0.005606</td>\n      <td>-0.012893</td>\n      <td>0.449439</td>\n      <td>0.506122</td>\n      <td>0.459099</td>\n      <td>0.444943</td>\n      <td>0.507964</td>\n      <td>0.460362</td>\n      <td>0.458845</td>\n      <td>...</td>\n      <td>0.087657</td>\n      <td>0.078005</td>\n      <td>0.003101</td>\n      <td>-0.007239</td>\n      <td>-0.006456</td>\n      <td>-0.004576</td>\n      <td>-0.748247</td>\n      <td>1.000000</td>\n      <td>0.545612</td>\n      <td>-0.605585</td>\n    </tr>\n    <tr>\n      <th>feature_561</th>\n      <td>0.030661</td>\n      <td>-0.016230</td>\n      <td>-0.028325</td>\n      <td>0.393059</td>\n      <td>0.425500</td>\n      <td>0.483420</td>\n      <td>0.389469</td>\n      <td>0.424472</td>\n      <td>0.480028</td>\n      <td>0.402871</td>\n      <td>...</td>\n      <td>0.058737</td>\n      <td>0.054001</td>\n      <td>-0.003234</td>\n      <td>-0.013146</td>\n      <td>-0.015371</td>\n      <td>-0.012552</td>\n      <td>-0.635230</td>\n      <td>0.545612</td>\n      <td>1.000000</td>\n      <td>-0.534107</td>\n    </tr>\n    <tr>\n      <th>activity</th>\n      <td>-0.004497</td>\n      <td>0.037329</td>\n      <td>0.043543</td>\n      <td>-0.729099</td>\n      <td>-0.816075</td>\n      <td>-0.775704</td>\n      <td>-0.725420</td>\n      <td>-0.817348</td>\n      <td>-0.781064</td>\n      <td>-0.729709</td>\n      <td>...</td>\n      <td>-0.220326</td>\n      <td>-0.207847</td>\n      <td>-0.007791</td>\n      <td>0.016710</td>\n      <td>0.020079</td>\n      <td>0.014390</td>\n      <td>0.613556</td>\n      <td>-0.605585</td>\n      <td>-0.534107</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>562 rows × 562 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "phoneData.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Data into training and testing\n",
    "x = phoneData.drop(\"activity\", axis=1)\n",
    "y = phoneData[[\"activity\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize Columns\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Accuracy: 18.69% || Time to Train: 1.219 seconds'"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# DT classifier, using entropy and a max depth of 5\n",
    "DT = tree.DecisionTreeClassifier(criterion=\"entropy\",max_depth=5)\n",
    "\n",
    "# using the function above, we can determine the accuracy and training time of a deciosion tree model\n",
    "model_acc_time(X_train, X_test, y_train, y_test, DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Accuracy: 17.77% || Time to Train: 6.614 seconds'"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# MLP Classifier \n",
    "MLP = MLPClassifier(max_iter=300, hidden_layer_sizes=(10,10), solver=\"sgd\")\n",
    "\n",
    "# calculating the accuracy and training time of an MLP Classifier\n",
    "model_acc_time(X_train, X_test, y_train, y_test, MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Accuracy: 18.54% || Time to Train: 6.470 seconds'"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Random Forest\n",
    "RF = RandomForestClassifier(n_estimators=200, max_depth=4,criterion=\"entropy\")\n",
    "\n",
    "# calculating the accuracy and training time of the random forest Classifier\n",
    "model_acc_time(X_train, X_test, y_train, y_test, RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Accuracy: 19.81% || Time to Train: 0.577 seconds'"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# Extra Trees Classifier\n",
    "ET = ExtraTreesClassifier(n_estimators=100, max_depth=3,criterion=\"entropy\")\n",
    "\n",
    "# calculating the accuracy and training time of the extra trees Classifier\n",
    "model_acc_time(X_train, X_test, y_train, y_test, ET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Accuracy: 17.77% || Time to Train: 0.833 seconds'"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# SGD Classifier\n",
    "SGD = SGDClassifier(loss=\"hinge\", max_iter=500, )\n",
    "\n",
    "# calculating the accuracy and training time of the SGD Classifier\n",
    "model_acc_time(X_train, X_test, y_train, y_test, SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Accuracy: 14.22% || Time to Train: 0.072 seconds'"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "GNB = GaussianNB()\n",
    "# calculating the accuracy and training time of the Gaussian Naive Bayes\n",
    "model_acc_time(X_train, X_test, y_train, y_test, GNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Accuracy: 17.09% || Time to Train: 6.346 seconds'"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# SVM\n",
    "SVM = svm.SVC(kernel=\"sigmoid\")\n",
    "\n",
    "# calculating the accuracy and training time of the SVM\n",
    "model_acc_time(X_train, X_test, y_train, y_test, SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}